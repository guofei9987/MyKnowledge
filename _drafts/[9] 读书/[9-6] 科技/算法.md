# 终极算法


## 机器学习主要有5个学派，
我们会对每个学派分别介绍：
- 符号学派将学习看作逆向演绎，并从哲学、心理学、逻辑学中寻求洞见；
- 联结学派对大脑进行逆向分析，灵感来源于神经科学和物理学；
- 进化学派在计算机上模拟进化，并利用遗传学和进化生物学知识；
- 贝叶斯学派认为学习是一种概率推理形式，理论根基在于统计学；
- 类推学派通过对相似性判断的外推来进行学习，并受心理学和数学最优化的影响。


在构建机器学习的目标推动下，我们将回顾过去100年的思想史，并以新的观点来看待这段历史。

### 联结学派

证明大脑皮层统一性的另一个证据来自所谓的基因组贫乏。人类大脑中的连接数量是基因组中字母数量的100万余倍，因此从物理角度，基因组不可能弄明白大脑构造的细节。



物理规律之美多大程度渗透到更高的领域（如生物学、社会学），这一点有待观察。但对混沌的研究提供了许多诱人的例子，这些例子和拥有相似行为的不同系统相关，而普适性理论可以解释这些例子。曼德布洛特集合（Mandelbrot Set）就是很完美的例子，能解释一个很简单的重复程序如何产生无数种类的形式。如果世界上的山峰、河流、云朵以及树木都是这些重复程序的产物（分形几何学表明它们就是），也许那些程序只是单个程序的不同参数化，而该单个程序可以从那些程序推导中得出。

### 符号学派

对于符号学派来说，所有的信息都可以简化为操作符号，就像数学家那样，为了解方程，会用其他表达式来代替本来的表达式。符号学者明白你不能从零开始学习：除了数据，你还需要一些原始的知识。他们已经弄明白，如何把先前存在的知识并入学习中，如何结合动态的知识来解决新问题。他们的主算法是逆向演绎，逆向演绎致力于弄明白，为了使演绎进展顺利，哪些知识被省略了，然后弄明白是什么让主算法变得越来越综合。



对于联结学派来说，学习就是大脑所做的事情，因此我们要做的就是对大脑进行逆向演绎。大脑通过调整神经元之间连接的强度来进行学习，关键问题是找到哪些连接导致了误差，以及如何纠正这些误差。联结学派的主算法是反向传播学习算法，该算法将系统的输出与想要的结果相比较，然后连续一层一层地改变神经元之间的连接，目的是为了使输出的东西接近想要的东西。


### 进化学派

进化学派认为，所有形式的学习都源于自然选择。如果自然选择造就我们，那么它就可以造就一切，我们要做的，就是在计算机上对它进行模仿。进化主义解决的关键问题是学习结构：不只是像反向传播那样调整参数，它还创造大脑，用来对参数进行微调。进化学派的主算法是基因编程，和自然使有机体交配和进化那样，基因编程也对计算机程序进行配对和提升。


### 贝叶斯学派

贝叶斯学派最关注的问题是不确定性。所有掌握的知识都有不确定性，而且学习知识的过程也是一种不确定的推理形式。那么问题就变成，在不破坏信息的情况下，如何处理嘈杂、不完整甚至自相矛盾的信息。解决的办法就是运用概率推理，而主算法就是贝叶斯定理及其衍生定理。贝叶斯定理告诉我们，如何将新的证据并入我们的信仰中，而概率推理算法尽可能有效地做到这一点。


朴素贝叶斯，HMM，贝叶斯网络  



### 类推学派

对于类推学派来说，学习的关键就是要在不同场景中认识到相似性，然后由此推导出其他相似性。如果两个病人有相似的症状，那么也许他们患有相同的疾病。问题的关键是，如何判断两个事物的相似程度。类推学派的主算法是支持向量机，主算法找出要记忆的经历，以及弄明白如何将这些经历结合起来，用来做新的预测。


刚开始发展缓慢，第一站是KNN，第二站是SVM，第三站是类比推理法。  


###





### 其它


遗传算法的经验会对支持“跳跃式进化”的一方有利。如果你运行10万代遗传算法，然后每隔1000代观察群体的数量，那么适应度与时间的曲线图可能看起来会像高低错落的楼梯，图形突然上升，然后是随着时间慢慢变长的平台期。要弄明白为什么也不难。一旦算法达到适应度的局部最大值（适应度中的峰值），算法会在这一点停很长时间，直到某次幸运的变异或者交叉，让处于坡上的个体等到更高的峰顶，在这一点上该个体会进行大量繁殖，然后和过往的每一代来爬上这个坡。当前的峰值越高，该过程发生前的那段时间就越长。当然，自然选择比这还要复杂：一个原因就是，环境可能会变化，要么是自然上的改变，要么是因为其他有机体自身进化了。另外，处于峰值的有机体可能会突然发现，对于再次进化，它面临巨大的压力。因此，虽然有用，当前的遗传算法还远远不是故事的结局。
